#!/usr/bin/env python3
"""
å¤´æ–‡ä»¶åˆ†æå™¨ - åˆ†æC/C++å¤´æ–‡ä»¶çš„includeå…³ç³»
"""

import os
import logging
from typing import List, Dict, Optional
from .file_extensions import is_header_file

logger = logging.getLogger(__name__)


class IncludeInfo:
    """åŒ…å«æ–‡ä»¶ä¿¡æ¯"""
    
    def __init__(self, include_path: str, line_number: int, file_path: str, 
                 is_system: bool = False):
        self.include_path = include_path
        self.line_number = line_number
        self.file_path = file_path
        self.is_system = is_system  # True: <header.h>, False: "header.h"
    
    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'include_path': self.include_path,
            'line_number': self.line_number,
            'file_path': self.file_path,
            'is_system': self.is_system,
            'include_type': 'system' if self.is_system else 'local'
        }


class HeaderAnalyzer:
    """å¤´æ–‡ä»¶includeåˆ†æå™¨"""
    
    def __init__(self, header_file: Optional[str] = None, config_file: Optional[str] = None):
        """åˆå§‹åŒ–å¤´æ–‡ä»¶åˆ†æå™¨
        
        Args:
            header_file: å•ä¸ªå¤´æ–‡ä»¶è·¯å¾„
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.header_file = header_file
        self.config_file = config_file
        self.config_parser = None
        self.includes = []  # å­˜å‚¨includeä¿¡æ¯
        self.dependency_graph = {}  # ä¾èµ–å›¾
        
        # é…ç½®logging
        self.logger = logging.getLogger(__name__)
    
    def analyze_single_file(self, file_path: str) -> Dict:
        """åˆ†æå•ä¸ªå¤´æ–‡ä»¶çš„includeå…³ç³»"""
        if not os.path.isfile(file_path):
            return {'error': f'æ–‡ä»¶ä¸å­˜åœ¨: {file_path}'}
        
        if not self._is_header_file(file_path):
            return {'error': f'ä¸æ˜¯å¤´æ–‡ä»¶: {file_path}'}
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            return {'error': f'æ— æ³•è¯»å–æ–‡ä»¶: {e}'}
        
        includes = self._extract_includes(content, file_path)
        
        return {
            'file_path': file_path,
            'file_name': os.path.basename(file_path),
            'includes': includes,
            'include_count': len(includes),
            'line_count': len(content.splitlines())
        }
    
    def analyze_file(self, file_path: str) -> Dict:
        """åˆ†æå•ä¸ªå¤´æ–‡ä»¶çš„includeå…³ç³»ï¼ˆå‘åå…¼å®¹ï¼‰"""
        return self.analyze_single_file(file_path)
    
    def analyze_from_repo(self, config_parser, target_files: List[str] = None) -> Dict:
        """
        ä»repoé…ç½®åˆ†æå¤´æ–‡ä»¶
        
        Args:
            config_parser: é…ç½®è§£æå™¨å¯¹è±¡
            target_files: æŒ‡å®šè¦åˆ†æçš„å¤´æ–‡ä»¶åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            å¤´æ–‡ä»¶åˆ†æç»“æœ
        """
        logger.info("å¼€å§‹å¤´æ–‡ä»¶æ‰¹é‡includeåˆ†æ")
        
        # æ”¶é›†è¦åˆ†æçš„å¤´æ–‡ä»¶
        header_files = self._collect_header_files_from_repo(config_parser, target_files)
        
        logger.info(f"æ‰¾åˆ° {len(header_files)} ä¸ªå¤´æ–‡ä»¶")
        
        if not header_files:
            return {
                'message': 'æœªæ‰¾åˆ°ä»»ä½•å¤´æ–‡ä»¶',
                'results': {},
                'summary': self._get_empty_summary()
            }
        
        # æ‰¹é‡åˆ†æ
        logger.info(f"æ‰¹é‡åˆ†æ {len(header_files)} ä¸ªå¤´æ–‡ä»¶")
        
        analysis_result = self.analyze_files(header_files)
        analysis_result['message'] = f'æˆåŠŸåˆ†æ {analysis_result["summary"]["total_files"]} ä¸ªå¤´æ–‡ä»¶'
        
        summary = analysis_result['summary']
        logger.info(f"å¤´æ–‡ä»¶åˆ†æå®Œæˆ: {summary['total_includes']} ä¸ªinclude")
        
        return analysis_result
    
    def analyze_from_single_file_mode(self, file_path: str) -> Dict:
        """
        å•æ–‡ä»¶æ¨¡å¼åˆ†æ
        
        Args:
            file_path: å¤´æ–‡ä»¶è·¯å¾„
            
        Returns:
            å¤´æ–‡ä»¶åˆ†æç»“æœ
        """
        logger.info("å¼€å§‹å•å¤´æ–‡ä»¶includeåˆ†æ")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¤´æ–‡ä»¶
        if not self._is_header_file(file_path):
            return {
                'message': 'ä¸æ˜¯å¤´æ–‡ä»¶',
                'results': {},
                'summary': {
                    'total_files': 0,
                    'total_includes': 0,
                    'system_includes': 0,
                    'local_includes': 0,
                    'errors': ['ä¸æ˜¯å¤´æ–‡ä»¶']
                }
            }
        
        logger.info("æ‰¾åˆ° 1 ä¸ªå¤´æ–‡ä»¶")
        file_name = os.path.basename(file_path)
        logger.info(f"åˆ†æå¤´æ–‡ä»¶: {file_name}")
        
        result = self.analyze_single_file(file_path)
        
        if 'error' in result:
            return {
                'message': f'åˆ†æå¤±è´¥: {result["error"]}',
                'results': {},
                'summary': {
                    'total_files': 1,
                    'total_includes': 0,
                    'system_includes': 0,
                    'local_includes': 0,
                    'errors': [result['error']]
                }
            }
        
        # è½¬æ¢ä¸ºæ‰¹é‡åˆ†ææ ¼å¼
        includes = result['includes']
        analysis_result = {
            'message': f'æˆåŠŸåˆ†æ 1 ä¸ªå¤´æ–‡ä»¶ï¼Œæ‰¾åˆ° {len(includes)} ä¸ªinclude',
            'results': {file_path: result},
            'summary': {
                'total_files': 1,
                'total_includes': len(includes),
                'system_includes': sum(1 for inc in includes if inc.is_system),
                'local_includes': sum(1 for inc in includes if not inc.is_system),
                'errors': []
            }
        }
        
        summary = analysis_result['summary']
        logger.info(f"å¤´æ–‡ä»¶åˆ†æå®Œæˆ: {summary['total_includes']} ä¸ªinclude")
        
        return analysis_result
    
    def analyze_files(self, file_paths: List[str]) -> Dict:
        """åˆ†æå¤šä¸ªå¤´æ–‡ä»¶"""
        results = {}
        summary = {
            'total_files': len(file_paths),
            'total_includes': 0,
            'system_includes': 0,
            'local_includes': 0,
            'errors': []
        }
        
        for file_path in file_paths:
            result = self.analyze_single_file(file_path)
            
            if 'error' in result:
                summary['errors'].append(result['error'])
            else:
                results[file_path] = result
                includes = result['includes']
                summary['total_includes'] += len(includes)
                summary['system_includes'] += sum(1 for inc in includes if inc.is_system)
                summary['local_includes'] += sum(1 for inc in includes if not inc.is_system)
        
        return {
            'results': results,
            'summary': summary
        }
    
    def _collect_header_files_from_repo(self, config_parser, target_files: List[str] = None) -> List[str]:
        """ä»repoé…ç½®æ”¶é›†è¦åˆ†æçš„å¤´æ–‡ä»¶"""
        if target_files:
            # ç”¨æˆ·æŒ‡å®šäº†ç‰¹å®šæ–‡ä»¶
            header_files = []
            for file_path in target_files:
                abs_path = os.path.abspath(file_path)
                if os.path.isfile(abs_path) and self._is_header_file(abs_path):
                    header_files.append(abs_path)
                else:
                    logger.warning(f"æŒ‡å®šçš„æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯å¤´æ–‡ä»¶: {file_path}")
            return header_files
        
        # æœªæŒ‡å®šæ–‡ä»¶ï¼šä»é…ç½®ä¸­æ”¶é›†æ‰€æœ‰å¤´æ–‡ä»¶
        all_files = []
        analysis_targets = config_parser.get_analysis_targets()
        
        for target_path in analysis_targets:
            if not os.path.exists(target_path):
                logger.warning(f"ç›®æ ‡è·¯å¾„ä¸å­˜åœ¨: {target_path}")
                continue
            
            if os.path.isfile(target_path):
                if self._is_header_file(target_path):
                    all_files.append(target_path)
            else:
                # ç›®å½•ï¼šæŸ¥æ‰¾æ‰€æœ‰å¤´æ–‡ä»¶
                header_files = self.find_all_headers(target_path)
                all_files.extend(header_files)
        
        # åº”ç”¨æ’é™¤è§„åˆ™
        return self._apply_exclusions_from_repo(config_parser, all_files)
    
    def _apply_exclusions_from_repo(self, config_parser, files: List[str]) -> List[str]:
        """åº”ç”¨repoé…ç½®çš„æ’é™¤è§„åˆ™è¿‡æ»¤æ–‡ä»¶"""
        exclude_targets = config_parser.get_exclude_targets()
        if not exclude_targets:
            return files
        
        filtered_files = []
        for file_path in files:
            should_exclude = False
            for exclude_target in exclude_targets:
                if exclude_target in file_path:
                    should_exclude = True
                    break
            
            if not should_exclude:
                filtered_files.append(file_path)
        
        return filtered_files
    
    def find_all_headers(self, directory: str) -> List[str]:
        """æŸ¥æ‰¾ç›®å½•ä¸‹çš„æ‰€æœ‰å¤´æ–‡ä»¶"""
        header_files = []
        
        if not os.path.isdir(directory):
            return header_files
        
        for root, dirs, files in os.walk(directory):
            for file in files:
                file_path = os.path.join(root, file)
                if self._is_header_file(file_path):
                    header_files.append(file_path)
        
        return header_files
    
    def _is_header_file(self, file_path: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯å¤´æ–‡ä»¶"""
        return is_header_file(file_path)
    
    def _extract_includes(self, content: str, file_path: str) -> List[IncludeInfo]:
        """æå–includeè¯­å¥"""
        includes = []
        lines = content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            
            # è·³è¿‡æ³¨é‡Šè¡Œ
            if line.startswith('//') or line.startswith('/*'):
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯includeæŒ‡ä»¤
            if line.startswith('#include'):
                include_info = self._parse_include_line(line, line_num, file_path)
                if include_info:
                    includes.append(include_info)
        
        return includes
    
    def _parse_include_line(self, line: str, line_num: int, file_path: str) -> Optional[IncludeInfo]:
        """è§£æincludeè¡Œ"""
        # ç§»é™¤ #include å‰ç¼€å’Œå¤šä½™ç©ºç™½
        content = line[8:].strip()  # len('#include') = 8
        
        if not content:
            return None
        
        # æ£€æŸ¥åŒ…å«ç±»å‹
        if content.startswith('<') and content.endswith('>'):
            # ç³»ç»Ÿå¤´æ–‡ä»¶: #include <header.h>
            include_path = content[1:-1]
            return IncludeInfo(include_path, line_num, file_path, is_system=True)
        elif content.startswith('"') and content.endswith('"'):
            # æœ¬åœ°å¤´æ–‡ä»¶: #include "header.h"
            include_path = content[1:-1]
            return IncludeInfo(include_path, line_num, file_path, is_system=False)
        else:
            # å…¶ä»–å½¢å¼ï¼ˆå¯èƒ½æ˜¯å®ï¼‰- å°è¯•æå–
            # ç§»é™¤å¯èƒ½çš„æ³¨é‡Š
            content = content.split('//')[0].split('/*')[0].strip()
            if content:
                return IncludeInfo(content, line_num, file_path, is_system=False)
        
        return None
    
    def _get_single_file_summary_text(self, file_path: str) -> str:
        """è·å–å•æ–‡ä»¶åˆ†æé…ç½®æ‘˜è¦æ–‡æœ¬"""
        return (f"ğŸ“‹ å•å¤´æ–‡ä»¶includeåˆ†ææ¨¡å¼:\n"
                f"   æ–‡ä»¶è·¯å¾„: {file_path}\n"
                f"   æ–‡ä»¶å: {os.path.basename(file_path)}\n"
                f"   â¤ åˆ†æå•ä¸ªå¤´æ–‡ä»¶çš„includeå…³ç³»")
    
    def _get_repo_summary_text(self, config_parser) -> str:
        """è·å–repoåˆ†æé…ç½®æ‘˜è¦æ–‡æœ¬"""
        return (f"ğŸ“‹ å¤´æ–‡ä»¶æ‰¹é‡includeåˆ†ææ¨¡å¼:\n"
                f"   â¤ åˆ†ææŒ‡å®šå¤´æ–‡ä»¶çš„includeå…³ç³»")
    
    def _get_empty_summary(self) -> dict:
        """è·å–ç©ºçš„ç»Ÿè®¡æ‘˜è¦"""
        return {
            'total_files': 0,
            'total_includes': 0,
            'system_includes': 0,
            'local_includes': 0,
            'errors': []
        }
    
    def get_dependency_graph(self, results: Dict) -> Dict[str, List[str]]:
        """è·å–ä¾èµ–å…³ç³»å›¾"""
        if not results or 'results' not in results:
            return {}
            
        graph = {}
        
        for file_path, result in results.get('results', {}).items():
            dependencies = []
            for include in result['includes']:
                dependencies.append(include.include_path)
            graph[file_path] = dependencies
        
        return graph
    
    def search_includes(self, results: Dict, pattern: str) -> List[Dict]:
        """æœç´¢åŒ…å«ç‰¹å®šæ¨¡å¼çš„include"""
        if not results or 'results' not in results:
            return []
            
        matches = []
        
        for file_path, result in results.get('results', {}).items():
            for include in result['includes']:
                if pattern.lower() in include.include_path.lower():
                    matches.append({
                        'file_path': file_path,
                        'file_name': os.path.basename(file_path),
                        'include_path': include.include_path,
                        'line_number': include.line_number,
                        'is_system': include.is_system
                    })
        
        return matches